{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "41f6baf1-2c65-4508-84eb-bf2187e83e18",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e30fa5c-183d-42fe-bf7d-e84eee82bf19",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pip install pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2284bee0-2c77-4845-89a8-5dbd061b1ab2",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e4097028-3e02-4d99-9d37-227ed7b4aad4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv(\"train.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "016eb98d-5127-49d3-8f16-18911b92d0bd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>title</th>\n",
       "      <th>author</th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>House Dem Aide: We Didn’t Even See Comey’s Let...</td>\n",
       "      <td>Darrell Lucus</td>\n",
       "      <td>House Dem Aide: We Didn’t Even See Comey’s Let...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>FLYNN: Hillary Clinton, Big Woman on Campus - ...</td>\n",
       "      <td>Daniel J. Flynn</td>\n",
       "      <td>Ever get the feeling your life circles the rou...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Why the Truth Might Get You Fired</td>\n",
       "      <td>Consortiumnews.com</td>\n",
       "      <td>Why the Truth Might Get You Fired October 29, ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>15 Civilians Killed In Single US Airstrike Hav...</td>\n",
       "      <td>Jessica Purkiss</td>\n",
       "      <td>Videos 15 Civilians Killed In Single US Airstr...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Iranian woman jailed for fictional unpublished...</td>\n",
       "      <td>Howard Portnoy</td>\n",
       "      <td>Print \\nAn Iranian woman has been sentenced to...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id                                              title              author  \\\n",
       "0   0  House Dem Aide: We Didn’t Even See Comey’s Let...       Darrell Lucus   \n",
       "1   1  FLYNN: Hillary Clinton, Big Woman on Campus - ...     Daniel J. Flynn   \n",
       "2   2                  Why the Truth Might Get You Fired  Consortiumnews.com   \n",
       "3   3  15 Civilians Killed In Single US Airstrike Hav...     Jessica Purkiss   \n",
       "4   4  Iranian woman jailed for fictional unpublished...      Howard Portnoy   \n",
       "\n",
       "                                                text  label  \n",
       "0  House Dem Aide: We Didn’t Even See Comey’s Let...      1  \n",
       "1  Ever get the feeling your life circles the rou...      0  \n",
       "2  Why the Truth Might Get You Fired October 29, ...      1  \n",
       "3  Videos 15 Civilians Killed In Single US Airstr...      1  \n",
       "4  Print \\nAn Iranian woman has been sentenced to...      1  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "427a3de9-e476-44d3-8312-02f30813405a",
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_to_drop=['id','author']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bbe632a4-5457-4af4-b50d-991cc54341f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=df.drop(columns=columns_to_drop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "59679301-d473-4a43-ab1f-24a6aef24ade",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>House Dem Aide: We Didn’t Even See Comey’s Let...</td>\n",
       "      <td>House Dem Aide: We Didn’t Even See Comey’s Let...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>FLYNN: Hillary Clinton, Big Woman on Campus - ...</td>\n",
       "      <td>Ever get the feeling your life circles the rou...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Why the Truth Might Get You Fired</td>\n",
       "      <td>Why the Truth Might Get You Fired October 29, ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>15 Civilians Killed In Single US Airstrike Hav...</td>\n",
       "      <td>Videos 15 Civilians Killed In Single US Airstr...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Iranian woman jailed for fictional unpublished...</td>\n",
       "      <td>Print \\nAn Iranian woman has been sentenced to...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title  \\\n",
       "0  House Dem Aide: We Didn’t Even See Comey’s Let...   \n",
       "1  FLYNN: Hillary Clinton, Big Woman on Campus - ...   \n",
       "2                  Why the Truth Might Get You Fired   \n",
       "3  15 Civilians Killed In Single US Airstrike Hav...   \n",
       "4  Iranian woman jailed for fictional unpublished...   \n",
       "\n",
       "                                                text  label  \n",
       "0  House Dem Aide: We Didn’t Even See Comey’s Let...      1  \n",
       "1  Ever get the feeling your life circles the rou...      0  \n",
       "2  Why the Truth Might Get You Fired October 29, ...      1  \n",
       "3  Videos 15 Civilians Killed In Single US Airstr...      1  \n",
       "4  Print \\nAn Iranian woman has been sentenced to...      1  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1efc6df6-0af6-4e1a-8ce0-b8e911152e9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_columns=['title','text']\n",
    "target=['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "96dcdf41-e227-406e-ace5-70b5bd1a96cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "X=df[selected_columns]\n",
    "y=df[target]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "af36f041-4e21-4530-a4f4-c47caebd3307",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>House Dem Aide: We Didn’t Even See Comey’s Let...</td>\n",
       "      <td>House Dem Aide: We Didn’t Even See Comey’s Let...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>FLYNN: Hillary Clinton, Big Woman on Campus - ...</td>\n",
       "      <td>Ever get the feeling your life circles the rou...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Why the Truth Might Get You Fired</td>\n",
       "      <td>Why the Truth Might Get You Fired October 29, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>15 Civilians Killed In Single US Airstrike Hav...</td>\n",
       "      <td>Videos 15 Civilians Killed In Single US Airstr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Iranian woman jailed for fictional unpublished...</td>\n",
       "      <td>Print \\nAn Iranian woman has been sentenced to...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title  \\\n",
       "0  House Dem Aide: We Didn’t Even See Comey’s Let...   \n",
       "1  FLYNN: Hillary Clinton, Big Woman on Campus - ...   \n",
       "2                  Why the Truth Might Get You Fired   \n",
       "3  15 Civilians Killed In Single US Airstrike Hav...   \n",
       "4  Iranian woman jailed for fictional unpublished...   \n",
       "\n",
       "                                                text  \n",
       "0  House Dem Aide: We Didn’t Even See Comey’s Let...  \n",
       "1  Ever get the feeling your life circles the rou...  \n",
       "2  Why the Truth Might Get You Fired October 29, ...  \n",
       "3  Videos 15 Civilians Killed In Single US Airstr...  \n",
       "4  Print \\nAn Iranian woman has been sentenced to...  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6ceb7614-f4fe-47af-8fed-7c995910140d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   label\n",
       "0      1\n",
       "1      0\n",
       "2      1\n",
       "3      1\n",
       "4      1"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "379d8032-44ca-4be3-8568-1db0e7dfbece",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pip install scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e7db74a3-6730-4c2a-a996-81fe46604bf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c1ea08aa-e4f0-4439-82fa-f814c2bb9bf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf=TfidfVectorizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8370982e-dad5-4e56-bde6-c17da6e5b29e",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_data=tfidf.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3269a879-d008-4c24-84c4-c677ad5316fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_df=pd.DataFrame(X_data.toarray(),columns=tfidf.get_feature_names_out())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8f9383ea-677c-464c-9310-7a46e57a35c0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   text  title\n",
       "0   0.0    1.0\n",
       "1   1.0    0.0"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ac4c1bb6-090f-466b-b871-bd76706052b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   text  title\n",
      "0   0.0    1.0\n",
      "1   1.0    0.0\n"
     ]
    }
   ],
   "source": [
    "print(tfidf_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a6978544-7366-4dfb-8f80-a0ef83598984",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import TextVectorization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "f2928a0d-22d7-4a24-a675-cd0afb62b02f",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = df['text']\n",
    "y = df[df.columns[2:]].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "3d7a854e-b944-4a02-9308-62b543d3b0bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of the dataset: 1300\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import TextVectorization\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Sample data (replace with your actual DataFrame)\n",
    "# df = pd.DataFrame({'comment_text': [...], ... })\n",
    "\n",
    "# Select the 'comment_text' and label columns\n",
    "x = df['text'].astype(str)  # Convert text to string to avoid any issues\n",
    "y = df[df.columns[2:]].values       # Assuming labels are in columns 2 and onwards\n",
    "\n",
    "# Handle missing values in 'comment_text' if necessary\n",
    "x = x.fillna('')  # Replace NaN with an empty string or some placeholder\n",
    "\n",
    "# Define TextVectorization layer\n",
    "MAX_FEATURES = 200000\n",
    "vectorizer = TextVectorization(\n",
    "    max_tokens=MAX_FEATURES,\n",
    "    output_sequence_length=1800,\n",
    "    output_mode='int'\n",
    ")\n",
    "\n",
    "# Adapt the vectorizer to the text data\n",
    "vectorizer.adapt(x)\n",
    "\n",
    "# Vectorize the text data\n",
    "vectorized_text = vectorizer(x)\n",
    "\n",
    "# Ensure vectorized_text is in the correct format for TensorFlow\n",
    "vectorized_text = tf.convert_to_tensor(vectorized_text)\n",
    "\n",
    "# Create a TensorFlow dataset\n",
    "dataset = tf.data.Dataset.from_tensor_slices((vectorized_text, y))\n",
    "\n",
    "# Dataset operations\n",
    "dataset = dataset.cache()\n",
    "dataset = dataset.shuffle(160000)  # Adjust buffer size if needed\n",
    "dataset = dataset.batch(16)\n",
    "dataset = dataset.prefetch(8)\n",
    "\n",
    "# Get the number of batches\n",
    "dataset_length = len(list(dataset))\n",
    "print(f\"Length of the dataset: {dataset_length}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86e52d13-9ca5-4f80-a213-fb70b7d57513",
   "metadata": {},
   "outputs": [],
   "source": [
    "test=pd.read_csv('test.csv//test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "2e86e061-7585-4799-86e4-35ffdae937bf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>title</th>\n",
       "      <th>author</th>\n",
       "      <th>text</th>\n",
       "      <th>Unnamed: 4</th>\n",
       "      <th>Unnamed: 5</th>\n",
       "      <th>Unnamed: 6</th>\n",
       "      <th>Unnamed: 7</th>\n",
       "      <th>Unnamed: 8</th>\n",
       "      <th>Unnamed: 9</th>\n",
       "      <th>...</th>\n",
       "      <th>Unnamed: 737</th>\n",
       "      <th>Unnamed: 738</th>\n",
       "      <th>Unnamed: 739</th>\n",
       "      <th>Unnamed: 740</th>\n",
       "      <th>Unnamed: 741</th>\n",
       "      <th>Unnamed: 742</th>\n",
       "      <th>Unnamed: 743</th>\n",
       "      <th>Unnamed: 744</th>\n",
       "      <th>Unnamed: 745</th>\n",
       "      <th>Unnamed: 746</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>20800</td>\n",
       "      <td>Specter of Trump Loosens Tongues, if Not Purse...</td>\n",
       "      <td>David Streitfeld</td>\n",
       "      <td>PALO ALTO, Calif.  —   After years of scorning...</td>\n",
       "      <td>PALO ALTO, Calif.  —   After years of scorning...</td>\n",
       "      <td>PALO ALTO, Calif.  —   After years of scorning...</td>\n",
       "      <td>PALO ALTO, Calif.  —   After years of scorning...</td>\n",
       "      <td>PALO ALTO, Calif.  —   After years of scorning...</td>\n",
       "      <td>PALO ALTO, Calif.  —   After years of scorning...</td>\n",
       "      <td>PALO ALTO, Calif.  —   After years of scorning...</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20801</td>\n",
       "      <td>Russian warships ready to strike terrorists ne...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Russian warships ready to strike terrorists ne...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>20802</td>\n",
       "      <td>#NoDAPL: Native American Leaders Vow to Stay A...</td>\n",
       "      <td>Common Dreams</td>\n",
       "      <td>Videos #NoDAPL: Native American Leaders Vow to...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>20803</td>\n",
       "      <td>Tim Tebow Will Attempt Another Comeback, This ...</td>\n",
       "      <td>Daniel Victor</td>\n",
       "      <td>If at first you don’t succeed, try a different...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20804</td>\n",
       "      <td>Keiser Report: Meme Wars (E995)</td>\n",
       "      <td>Truth Broadcast Network</td>\n",
       "      <td>42 mins ago 1 Views 0 Comments 0 Likes 'For th...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 747 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      id                                              title  \\\n",
       "0  20800  Specter of Trump Loosens Tongues, if Not Purse...   \n",
       "1  20801  Russian warships ready to strike terrorists ne...   \n",
       "2  20802  #NoDAPL: Native American Leaders Vow to Stay A...   \n",
       "3  20803  Tim Tebow Will Attempt Another Comeback, This ...   \n",
       "4  20804                    Keiser Report: Meme Wars (E995)   \n",
       "\n",
       "                    author                                               text  \\\n",
       "0         David Streitfeld  PALO ALTO, Calif.  —   After years of scorning...   \n",
       "1                      NaN  Russian warships ready to strike terrorists ne...   \n",
       "2            Common Dreams  Videos #NoDAPL: Native American Leaders Vow to...   \n",
       "3            Daniel Victor  If at first you don’t succeed, try a different...   \n",
       "4  Truth Broadcast Network  42 mins ago 1 Views 0 Comments 0 Likes 'For th...   \n",
       "\n",
       "                                          Unnamed: 4  \\\n",
       "0  PALO ALTO, Calif.  —   After years of scorning...   \n",
       "1                                                NaN   \n",
       "2                                                NaN   \n",
       "3                                                NaN   \n",
       "4                                                NaN   \n",
       "\n",
       "                                          Unnamed: 5  \\\n",
       "0  PALO ALTO, Calif.  —   After years of scorning...   \n",
       "1                                                NaN   \n",
       "2                                                NaN   \n",
       "3                                                NaN   \n",
       "4                                                NaN   \n",
       "\n",
       "                                          Unnamed: 6  \\\n",
       "0  PALO ALTO, Calif.  —   After years of scorning...   \n",
       "1                                                NaN   \n",
       "2                                                NaN   \n",
       "3                                                NaN   \n",
       "4                                                NaN   \n",
       "\n",
       "                                          Unnamed: 7  \\\n",
       "0  PALO ALTO, Calif.  —   After years of scorning...   \n",
       "1                                                NaN   \n",
       "2                                                NaN   \n",
       "3                                                NaN   \n",
       "4                                                NaN   \n",
       "\n",
       "                                          Unnamed: 8  \\\n",
       "0  PALO ALTO, Calif.  —   After years of scorning...   \n",
       "1                                                NaN   \n",
       "2                                                NaN   \n",
       "3                                                NaN   \n",
       "4                                                NaN   \n",
       "\n",
       "                                          Unnamed: 9  ... Unnamed: 737  \\\n",
       "0  PALO ALTO, Calif.  —   After years of scorning...  ...          NaN   \n",
       "1                                                NaN  ...          NaN   \n",
       "2                                                NaN  ...          NaN   \n",
       "3                                                NaN  ...          NaN   \n",
       "4                                                NaN  ...          NaN   \n",
       "\n",
       "  Unnamed: 738 Unnamed: 739 Unnamed: 740 Unnamed: 741 Unnamed: 742  \\\n",
       "0          NaN          NaN          NaN          NaN          NaN   \n",
       "1          NaN          NaN          NaN          NaN          NaN   \n",
       "2          NaN          NaN          NaN          NaN          NaN   \n",
       "3          NaN          NaN          NaN          NaN          NaN   \n",
       "4          NaN          NaN          NaN          NaN          NaN   \n",
       "\n",
       "  Unnamed: 743 Unnamed: 744 Unnamed: 745 Unnamed: 746  \n",
       "0          NaN          NaN          NaN          NaN  \n",
       "1          NaN          NaN          NaN          NaN  \n",
       "2          NaN          NaN          NaN          NaN  \n",
       "3          NaN          NaN          NaN          NaN  \n",
       "4          NaN          NaN          NaN          NaN  \n",
       "\n",
       "[5 rows x 747 columns]"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "dfe72219-fc47-4d69-af00-3edc6b0012f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "test=test.drop(columns=columns_to_drop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "861babc3-e9b7-4e3e-9ce1-2177d4c9d2a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test = df['text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "2cbefcae-9370-4a6e-bb83-c4ba6fa41f72",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of the dataset: 1300\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import TextVectorization\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Sample data (replace with your actual DataFrame)\n",
    "# df = pd.DataFrame({'comment_text': [...], ... })\n",
    "\n",
    "# Select the 'comment_text' and label columns\n",
    "x_test = df['text'].astype(str)  # Convert text to string to avoid any issues\n",
    "\n",
    "# Handle missing values in 'comment_text' if necessary\n",
    "x_test = x_test.fillna('')  # Replace NaN with an empty string or some placeholder\n",
    "\n",
    "# Define TextVectorization layer\n",
    "MAX_FEATURES = 200000\n",
    "vectorizer = TextVectorization(\n",
    "    max_tokens=MAX_FEATURES,\n",
    "    output_sequence_length=1800,\n",
    "    output_mode='int'\n",
    ")\n",
    "\n",
    "# Adapt the vectorizer to the text data\n",
    "vectorizer.adapt(x_test)\n",
    "\n",
    "# Vectorize the text data\n",
    "vectorized_text = vectorizer(x_test)\n",
    "\n",
    "# Ensure vectorized_text is in the correct format for TensorFlow\n",
    "vectorized_text = tf.convert_to_tensor(vectorized_text)\n",
    "\n",
    "# Create a TensorFlow dataset\n",
    "dataset_test = tf.data.Dataset.from_tensor_slices((vectorized_text))\n",
    "\n",
    "# Dataset operations\n",
    "dataset_test = dataset_test.cache()\n",
    "dataset_test= dataset_test.shuffle(160000)  # Adjust buffer size if needed\n",
    "dataset_test = dataset_test.batch(16)\n",
    "dataset_test= dataset_test.prefetch(8)\n",
    "\n",
    "# Get the number of batches\n",
    "dataset_length_test = len(list(dataset_test))\n",
    "print(f\"Length of the dataset: {dataset_length_test}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "f6e041fc-404b-4f32-b265-470c12192e58",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set length: 909\n",
      "Validation set length: 260\n",
      "Test set length: 130\n"
     ]
    }
   ],
   "source": [
    "# Split the dataset into training, validation, and test sets\n",
    "train = dataset.take(int(len(dataset) * 0.7))\n",
    "val = dataset.skip(int(len(dataset) * 0.7)).take(int(len(dataset) * 0.2))\n",
    "test = dataset.skip(int(len(dataset) * 0.9)).take(int(len(dataset) * 0.1))\n",
    "\n",
    "# Verify the lengths\n",
    "print(f\"Training set length: {len(list(train))}\")\n",
    "print(f\"Validation set length: {len(list(val))}\")\n",
    "print(f\"Test set length: {len(list(test))}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d358d2fc-c4d9-4739-9c3b-603afab3593c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM,Dropout,Bidirectional,Dense,Embedding\n",
    "from tensorflow.keras.utils import plot_model\n",
    "model = Sequential()\n",
    "model.add(Embedding(MAX_FEATURES+1, 32))\n",
    "\n",
    "model.add(Bidirectional(LSTM(32 , activation = 'tanh')))\n",
    "model.summary()\n",
    "plot_model(model, to_file='model_plot.png', show_shapes=True, show_layer_names=True)\n",
    "model.add(Dense(128,activation = 'relu'))\n",
    "model.summary()\n",
    "\n",
    "model.compile(loss='binary_crossentropy', optimizer='Adam')\n",
    "model.add(Dense(256,activation = 'relu'))\n",
    "model.add(Dense(128,activation = 'relu'))\n",
    "\n",
    "model.add(Dense(1,activation = 'sigmoid'))\n",
    "model.compile(loss='binary_crossentropy', optimizer='Adam')\n",
    "model.summary()\n",
    "plot_model(model, to_file='model_plot.png', show_shapes=True, show_layer_names=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fba2905-5d8c-4c5c-843f-00b0704cb4d8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pip install pydot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3366141c-8328-44ad-b807-4b9b00c7db78",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "history = model.fit(train, epochs=10, validation_data=val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "0d874b92-d07e-44f6-9f10-444b2ffc8f5b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 514ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[1]])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_text = vectorizer('Russian warships ready to strike terrorists near Aleppo 08.11.2016 | Source: Source: Mil.ru Attack aircraft of the Russian aircraft carrier Admiral Kuznetsov get ready to strike terrorists positions in the vicinity of Aleppo, sources at the Russian Defense Ministry said, RBC reports. Insurgents attempts to break into Aleppo from outside are meaningless,\" the source said. The main task of the aircraft carrier aviation group is to strike missile and air blows on the terrorists , whose goal is to enter Aleppo. After the attacks on terrorists positions, one will have to forget about the support for insurgents from the outside, the source said. The Russian group in the Mediterranean Sea consists of the Admiral Kuznetsov aircraft carrier , the heavy nuclear missile cruiser Pyotr Velikiy (Peter the Great) and large anti-submarine ships Severomorsk and Vice-Admiral Kulakov. Russia has increased intelligence activities in Syria to establish the areas, where terrorists are concentrated, as well as the routes that they use to move from one area to another. The militants took advantage of the humanitarian pause and regrouped their forces to prepare for a new breakthrough into the eastern part of Aleppo,\" the source added. According to the source, Russia will use new weapons during the upcoming attacks on terrorists . It was said that the Russian warships in the Mediterranean Sea will launch Caliber cruise missiles, although it was not specified which ships would be responsible for the launches. Pravda.Ru Russian warships travel to Syria')\n",
    "res = model.predict(np.expand_dims(input_text,0))\n",
    "(res > 0.5).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19d68363-61c7-46a7-8d5e-c3415e3da806",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pip install gradio\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d789162-ff87-40c3-bf4d-93bb2da0ecfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming 'model' is your Keras model\n",
    "model.save('my_model.h5')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eaae21c2-0196-44e7-8bad-76e61579141d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "model = tf.keras.models.load_model('my_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "3e3a7bb7-b980-4fb6-989f-560853ef3d64",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "import pickle\n",
    "tokenizer = Tokenizer(num_words=10000)  # Adjust the number based on your dataset\n",
    "# Fit the tokenizer on your training data during the training process:\n",
    "tokenizer.fit_on_texts(x)\n",
    "# Save the tokenizer:\n",
    "with open('tokenizer.pickle', 'wb') as handle:\n",
    "    pickle.dump(tokenizer, handle, protocol=pickle.HIGHEST_PROTOCOL)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "50951e48-b23c-4f8a-a5ef-e1fffa46fc66",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "import pickle\n",
    "\n",
    "\n",
    "# Create and fit the vectorizer\n",
    "vectorizer = CountVectorizer()\n",
    "vectorizer.fit(x)\n",
    "\n",
    "# Save the vectorizer\n",
    "with open('vectorizer.pickle', 'wb') as vectorizer_file:\n",
    "    pickle.dump(vectorizer, vectorizer_file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b76688e5-9723-4795-8581-bc51906f997c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Hp\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\base.py:376: InconsistentVersionWarning: Trying to unpickle estimator CountVectorizer from version 1.0.2 when using version 1.5.1. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on local URL:  http://127.0.0.1:7860\n",
      "\n",
      "To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7860/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 17s 17s/step\n",
      "1/1 [==============================] - 14s 14s/step\n",
      "1/1 [==============================] - 14s 14s/step\n",
      "1/1 [==============================] - 13s 13s/step\n"
     ]
    }
   ],
   "source": [
    "import gradio as gr\n",
    "import numpy as np\n",
    "import pickle\n",
    "import tensorflow as tf\n",
    "\n",
    "# Load your model and vectorizer\n",
    "model = tf.keras.models.load_model('my_model.h5')\n",
    "\n",
    "with open('vectorizer.pickle', 'rb') as vectorizer_file:\n",
    "    vectorizer = pickle.load(vectorizer_file)\n",
    "\n",
    "def predict_fake_news(input_text):\n",
    "    # Vectorize the input text\n",
    "    input_vector = vectorizer.transform([input_text])\n",
    "    \n",
    "    # Make prediction\n",
    "    res = model.predict(input_vector)\n",
    "    \n",
    "    # Return prediction result (1 for fake news, 0 for real news)\n",
    "    return int(res[0])\n",
    "\n",
    "# Create Gradio interface\n",
    "iface = gr.Interface(\n",
    "    fn=predict_fake_news,\n",
    "    inputs=gr.Textbox(label=\"Enter news article text\"),\n",
    "    outputs=gr.Label(label=\"Prediction (1: Fake News, 0: Real News)\"),\n",
    "    title=\"Fake News Detector\",\n",
    "    description=\"Enter a news article to predict if it's fake or real.\"\n",
    ")\n",
    "\n",
    "# Launch the interface\n",
    "iface.launch()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66dd8b64-c9a5-4bf6-adfa-53c0d1f9eade",
   "metadata": {},
   "source": [
    "## "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
